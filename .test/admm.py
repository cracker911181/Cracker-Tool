
from threading import Thread as pool
import urllib.request
import requests
import base64
import sys,os,time

#cracker
#logo():
        #creator:cracker911181
import os
import time
import sys

#text colour()
#creator: CRACKER911181

white = '\33[00m'
red = '\33[91m'
green = '\33[92m'
yellow = '\33[93m'
blue = '\33[94m'
rosy = '\33[95m'
pest = '\33[96m'




############################
link = str(input(rosy+"\nEnter Your Target Website (eg: 'www.google.com'): "))

try:
	print(yellow+"\n      ߎ탯nnecting To Server...")
	lnk=str("http://"+link+":80")
	requests.get(lnk)
	print(green+"\n       ‼️️Connected‼️   ️")
	pass
except ConnectionResetError:
	print(red+"\n      ❌Not Connected❌️   ")
	sys.exit()
except requests.exceptions.ConnectionError:
	print(red+"\n  ⚠Try Again With a valid URL⚠️    ️")
	sys.exit()
except requests.exceptions.InvalidURL:
	print(red+"\n        ߚ땒L Not Validߚ렠 ")
	sys.exit()

print(pest+"\n\n")
suba=open("a_link.txt","r")
subad=suba.read()
ascii_de=subad.encode("ascii") 
decode=base64.b64decode(ascii_de) 
subadmin=decode.decode("ascii")
sp=subadmin.split("\n")




def find0():
	ss=sp[0:7]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(pest+url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find1():
	ss=sp[7:14]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue
		


#############################



def find2():
	ss=sp[14:21]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find3():
	ss=sp[21:28]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find4():
	ss=sp[28:35]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find5():
	ss=sp[35:42]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find6():
	ss=sp[42:49]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find7():
	ss=sp[49:56]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find8():
	ss=sp[56:63]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find9():
	ss=sp[63:70]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find10():
	ss=sp[70:77]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find11():
	ss=sp[77:84]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find12():
	ss=sp[84:91]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find13():
	ss=sp[91:98]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find14():
	ss=sp[98:105]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find15():
	ss=sp[105:112]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find16():
	ss=sp[112:119]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find17():
	ss=sp[119:126]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find18():
	ss=sp[126:133]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find19():
	ss=sp[133:140]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find20():
	ss=sp[140:147]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find21():
	ss=sp[147:154]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find22():
	ss=sp[154:161]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find23():
	ss=sp[161:168]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find24():
	ss=sp[168:175]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find25():
	ss=sp[175:182]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find26():
	ss=sp[182:189]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find27():
	ss=sp[189:196]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find28():
	ss=sp[196:203]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find29():
	ss=sp[203:210]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find30():
	ss=sp[210:217]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find31():
	ss=sp[217:224]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find32():
	ss=sp[224:231]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find33():
	ss=sp[231:238]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find34():
	ss=sp[238:245]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find35():
	ss=sp[245:252]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find36():
	ss=sp[252:259]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find37():
	ss=sp[259:266]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find38():
	ss=sp[266:273]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find39():
	ss=sp[273:280]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find40():
	ss=sp[280:287]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find41():
	ss=sp[287:294]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find42():
	ss=sp[294:301]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find43():
	ss=sp[301:308]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find44():
	ss=sp[308:315]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find45():
	ss=sp[315:322]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find46():
	ss=sp[322:329]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find47():
	ss=sp[329:336]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find48():
	ss=sp[336:343]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find49():
	ss=sp[343:350]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find50():
	ss=sp[350:357]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find51():
	ss=sp[357:364]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find52():
	ss=sp[364:371]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find53():
	ss=sp[371:378]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find54():
	ss=sp[378:385]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find55():
	ss=sp[385:392]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find56():
	ss=sp[392:399]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find57():
	ss=sp[399:406]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find58():
	ss=sp[406:413]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find59():
	ss=sp[413:420]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find60():
	ss=sp[420:427]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find61():
	ss=sp[427:434]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find62():
	ss=sp[434:441]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find63():
	ss=sp[441:448]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find64():
	ss=sp[448:455]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find65():
	ss=sp[455:462]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find66():
	ss=sp[462:469]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find67():
	ss=sp[469:476]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find68():
	ss=sp[476:483]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find69():
	ss=sp[483:490]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find70():
	ss=sp[490:497]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find71():
	ss=sp[497:504]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find72():
	ss=sp[504:511]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find73():
	ss=sp[511:518]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find74():
	ss=sp[518:525]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find75():
	ss=sp[525:532]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find76():
	ss=sp[532:539]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find77():
	ss=sp[539:546]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find78():
	ss=sp[546:553]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find79():
	ss=sp[553:560]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find80():
	ss=sp[560:567]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find81():
	ss=sp[567:574]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find82():
	ss=sp[574:581]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find83():
	ss=sp[581:588]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find84():
	ss=sp[588:595]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find85():
	ss=sp[595:602]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find86():
	ss=sp[602:609]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find87():
	ss=sp[609:616]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find88():
	ss=sp[616:623]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find89():
	ss=sp[623:630]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find90():
	ss=sp[630:637]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find91():
	ss=sp[637:644]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find92():
	ss=sp[644:651]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find93():
	ss=sp[651:658]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find94():
	ss=sp[658:665]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find95():
	ss=sp[665:672]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find96():
	ss=sp[672:679]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find97():
	ss=sp[679:686]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find98():
	ss=sp[686:693]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find99():
	ss=sp[693:700]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find100():
	ss=sp[700:707]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find101():
	ss=sp[707:714]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find102():
	ss=sp[714:721]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find103():
	ss=sp[721:728]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find104():
	ss=sp[728:735]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find105():
	ss=sp[735:742]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find106():
	ss=sp[742:749]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find107():
	ss=sp[749:756]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find108():
	ss=sp[756:763]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find109():
	ss=sp[763:770]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find110():
	ss=sp[770:777]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find111():
	ss=sp[777:784]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find112():
	ss=sp[784:791]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find113():
	ss=sp[791:798]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find114():
	ss=sp[798:805]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find115():
	ss=sp[805:812]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find116():
	ss=sp[812:819]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find117():
	ss=sp[819:826]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find118():
	ss=sp[826:833]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find119():
	ss=sp[833:840]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find120():
	ss=sp[840:847]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find121():
	ss=sp[847:854]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find122():
	ss=sp[854:861]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find123():
	ss=sp[861:868]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find124():
	ss=sp[868:875]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find125():
	ss=sp[875:882]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find126():
	ss=sp[882:889]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find127():
	ss=sp[889:896]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find128():
	ss=sp[896:903]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find129():
	ss=sp[903:910]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find130():
	ss=sp[910:917]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find131():
	ss=sp[917:924]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find132():
	ss=sp[924:931]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find133():
	ss=sp[931:938]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find134():
	ss=sp[938:945]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find135():
	ss=sp[945:952]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find136():
	ss=sp[952:959]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find137():
	ss=sp[959:966]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find138():
	ss=sp[966:973]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find139():
	ss=sp[973:980]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find140():
	ss=sp[980:987]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find141():
	ss=sp[987:994]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find142():
	ss=sp[994:1001]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find143():
	ss=sp[1001:1008]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find144():
	ss=sp[1008:1015]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find145():
	ss=sp[1015:1022]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find146():
	ss=sp[1022:1029]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find147():
	ss=sp[1029:1036]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find148():
	ss=sp[1036:1043]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find149():
	ss=sp[1043:1050]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find150():
	ss=sp[1050:1057]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find151():
	ss=sp[1057:1064]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find152():
	ss=sp[1064:1071]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find153():
	ss=sp[1071:1078]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find154():
	ss=sp[1078:1085]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find155():
	ss=sp[1085:1092]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find156():
	ss=sp[1092:1099]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find157():
	ss=sp[1099:1106]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find158():
	ss=sp[1106:1113]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find159():
	ss=sp[1113:1120]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find160():
	ss=sp[1120:1127]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find161():
	ss=sp[1127:1134]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find162():
	ss=sp[1134:1141]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find163():
	ss=sp[1141:1148]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find164():
	ss=sp[1148:1155]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find165():
	ss=sp[1155:1162]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find166():
	ss=sp[1162:1169]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find167():
	ss=sp[1169:1176]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find168():
	ss=sp[1176:1183]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find169():
	ss=sp[1183:1190]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find170():
	ss=sp[1190:1197]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find171():
	ss=sp[1197:1204]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find172():
	ss=sp[1204:1211]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find173():
	ss=sp[1211:1218]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################


def final():

	t0=pool(target=find0)
	t1=pool(target=find1)
	t2=pool(target=find2)
	t3=pool(target=find3)
	t4=pool(target=find4)
	t5=pool(target=find5)
	t6=pool(target=find6)
	t7=pool(target=find7)
	t8=pool(target=find8)
	t9=pool(target=find9)
	t10=pool(target=find10)
	t11=pool(target=find11)
	t12=pool(target=find12)
	t13=pool(target=find13)
	t14=pool(target=find14)
	t15=pool(target=find15)
	t16=pool(target=find16)
	t17=pool(target=find17)
	t18=pool(target=find18)
	t19=pool(target=find19)
	t20=pool(target=find20)
	t21=pool(target=find21)
	t22=pool(target=find22)
	t23=pool(target=find23)
	t24=pool(target=find24)
	t25=pool(target=find25)
	t26=pool(target=find26)
	t27=pool(target=find27)
	t28=pool(target=find28)
	t29=pool(target=find29)
	t30=pool(target=find30)
	t31=pool(target=find31)
	t32=pool(target=find32)
	t33=pool(target=find33)
	t34=pool(target=find34)
	t35=pool(target=find35)
	t36=pool(target=find36)
	t37=pool(target=find37)
	t38=pool(target=find38)
	t39=pool(target=find39)
	t40=pool(target=find40)
	t41=pool(target=find41)
	t42=pool(target=find42)
	t43=pool(target=find43)
	t44=pool(target=find44)
	t45=pool(target=find45)
	t46=pool(target=find46)
	t47=pool(target=find47)
	t48=pool(target=find48)
	t49=pool(target=find49)
	t50=pool(target=find50)
	t51=pool(target=find51)
	t52=pool(target=find52)
	t53=pool(target=find53)
	t54=pool(target=find54)
	t55=pool(target=find55)
	t56=pool(target=find56)
	t57=pool(target=find57)
	t58=pool(target=find58)
	t59=pool(target=find59)
	t60=pool(target=find60)
	t61=pool(target=find61)
	t62=pool(target=find62)
	t63=pool(target=find63)
	t64=pool(target=find64)
	t65=pool(target=find65)
	t66=pool(target=find66)
	t67=pool(target=find67)
	t68=pool(target=find68)
	t69=pool(target=find69)
	t70=pool(target=find70)
	t71=pool(target=find71)
	t72=pool(target=find72)
	t73=pool(target=find73)
	t74=pool(target=find74)
	t75=pool(target=find75)
	t76=pool(target=find76)
	t77=pool(target=find77)
	t78=pool(target=find78)
	t79=pool(target=find79)
	t80=pool(target=find80)
	t81=pool(target=find81)
	t82=pool(target=find82)
	t83=pool(target=find83)
	t84=pool(target=find84)
	t85=pool(target=find85)
	t86=pool(target=find86)
	t87=pool(target=find87)
	t88=pool(target=find88)
	t89=pool(target=find89)
	t90=pool(target=find90)
	t91=pool(target=find91)
	t92=pool(target=find92)
	t93=pool(target=find93)
	t94=pool(target=find94)
	t95=pool(target=find95)
	t96=pool(target=find96)
	t97=pool(target=find97)
	t98=pool(target=find98)
	t99=pool(target=find99)
	t100=pool(target=find100)
	t101=pool(target=find101)
	t102=pool(target=find102)
	t103=pool(target=find103)
	t104=pool(target=find104)
	t105=pool(target=find105)
	t106=pool(target=find106)
	t107=pool(target=find107)
	t108=pool(target=find108)
	t109=pool(target=find109)
	t110=pool(target=find110)
	t111=pool(target=find111)
	t112=pool(target=find112)
	t113=pool(target=find113)
	t114=pool(target=find114)
	t115=pool(target=find115)
	t116=pool(target=find116)
	t117=pool(target=find117)
	t118=pool(target=find118)
	t119=pool(target=find119)
	t120=pool(target=find120)
	t121=pool(target=find121)
	t122=pool(target=find122)
	t123=pool(target=find123)
	t124=pool(target=find124)
	t125=pool(target=find125)
	t126=pool(target=find126)
	t127=pool(target=find127)
	t128=pool(target=find128)
	t129=pool(target=find129)
	t130=pool(target=find130)
	t131=pool(target=find131)
	t132=pool(target=find132)
	t133=pool(target=find133)
	t134=pool(target=find134)
	t135=pool(target=find135)
	t136=pool(target=find136)
	t137=pool(target=find137)
	t138=pool(target=find138)
	t139=pool(target=find139)
	t140=pool(target=find140)
	t141=pool(target=find141)
	t142=pool(target=find142)
	t143=pool(target=find143)
	t144=pool(target=find144)
	t145=pool(target=find145)
	t146=pool(target=find146)
	t147=pool(target=find147)
	t148=pool(target=find148)
	t149=pool(target=find149)
	t150=pool(target=find150)
	t151=pool(target=find151)
	t152=pool(target=find152)
	t153=pool(target=find153)
	t154=pool(target=find154)
	t155=pool(target=find155)
	t156=pool(target=find156)
	t157=pool(target=find157)
	t158=pool(target=find158)
	t159=pool(target=find159)
	t160=pool(target=find160)
	t161=pool(target=find161)
	t162=pool(target=find162)
	t163=pool(target=find163)
	t164=pool(target=find164)
	t165=pool(target=find165)
	t166=pool(target=find166)
	t167=pool(target=find167)
	t168=pool(target=find168)
	t169=pool(target=find169)
	t170=pool(target=find170)
	t171=pool(target=find171)
	t172=pool(target=find172)
	t173=pool(target=find173)
	
	t0.start()
	t1.start()
	t2.start()
	t3.start()
	t4.start()
	t5.start()
	t6.start()
	t7.start()
	t8.start()
	t9.start()
	t10.start()
	t11.start()
	t12.start()
	t13.start()
	t14.start()
	t15.start()
	t16.start()
	t17.start()
	t18.start()
	t19.start()
	t20.start()
	t21.start()
	t22.start()
	t23.start()
	t24.start()
	t25.start()
	t26.start()
	t27.start()
	t28.start()
	t29.start()
	t30.start()
	t31.start()
	t32.start()
	t33.start()
	t34.start()
	t35.start()
	t36.start()
	t37.start()
	t38.start()
	t39.start()
	t40.start()
	t41.start()
	t42.start()
	t43.start()
	t44.start()
	t45.start()
	t46.start()
	t47.start()
	t48.start()
	t49.start()
	t50.start()
	t51.start()
	t52.start()
	t53.start()
	t54.start()
	t55.start()
	t56.start()
	t57.start()
	t58.start()
	t59.start()
	t60.start()
	t61.start()
	t62.start()
	t63.start()
	t64.start()
	t65.start()
	t66.start()
	t67.start()
	t68.start()
	t69.start()
	t70.start()
	t71.start()
	t72.start()
	t73.start()
	t74.start()
	t75.start()
	t76.start()
	t77.start()
	t78.start()
	t79.start()
	t80.start()
	t81.start()
	t82.start()
	t83.start()
	t84.start()
	t85.start()
	t86.start()
	t87.start()
	t88.start()
	t89.start()
	t90.start()
	t91.start()
	t92.start()
	t93.start()
	t94.start()
	t95.start()
	t96.start()
	t97.start()
	t98.start()
	t99.start()
	t100.start()
	t101.start()
	t102.start()
	t103.start()
	t104.start()
	t105.start()
	t106.start()
	t107.start()
	t108.start()
	t109.start()
	t110.start()
	t111.start()
	t112.start()
	t113.start()
	t114.start()
	t115.start()
	t116.start()
	t117.start()
	t118.start()
	t119.start()
	t120.start()
	t121.start()
	t122.start()
	t123.start()
	t124.start()
	t125.start()
	t126.start()
	t127.start()
	t128.start()
	t129.start()
	t130.start()
	t131.start()
	t132.start()
	t133.start()
	t134.start()
	t135.start()
	t136.start()
	t137.start()
	t138.start()
	t139.start()
	t140.start()
	t141.start()
	t142.start()
	t143.start()
	t144.start()
	t145.start()
	t146.start()
	t147.start()
	t148.start()
	t149.start()
	t150.start()
	t151.start()
	t152.start()
	t153.start()
	t154.start()
	t155.start()
	t156.start()
	t157.start()
	t158.start()
	t159.start()
	t160.start()
	t161.start()
	t162.start()
	t163.start()
	t164.start()
	t165.start()
	t166.start()
	t167.start()
	t168.start()
	t169.start()
	t170.start()
	t171.start()
	t172.start()
	t173.start()


final()